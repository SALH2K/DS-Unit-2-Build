{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS Unit 2 Build.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl1bMW4CgIbV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeAMTFCXgIbc"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btodKdqVOJRo",
        "outputId": "37e3b5b4-1a54-4d61-c2b0-3d110ddadf30"
      },
      "source": [
        "!pip install category_encoders==2.*\n",
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.22.2.post1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.19.5)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.1.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Requirement already satisfied: eli5 in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (20.3.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qas2Xgw-gIbd"
      },
      "source": [
        "# Boosting and Permutation Importance\n",
        "\n",
        "- Use xgboost for **gradient boosting**\n",
        "- Get **permutation importances** for model interpretation and feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjyjpUaKIPys"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import GradientBoostingClassifier # New model\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.inspection import permutation_importance # For interpretability\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from xgboost import XGBClassifier # Another implementation of new model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGRKs0WOeRs"
      },
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['CommViolPredUnnormalizedData.txt']), na_values=['?'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zHJekCwgIbe"
      },
      "source": [
        "## Wrangle Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJtZSdIRgIbf"
      },
      "source": [
        "# def wrangle(fm_path, tv_path=None):\n",
        "#     if tv_path:\n",
        "#         df = pd.merge(pd.read_csv(fm_path, parse_dates=['date_recorded'], na_values=[-2e-08, 0]), \n",
        "#                          pd.read_csv(tv_path)).set_index('date_recorded')\n",
        "\n",
        "#     else:\n",
        "#         df = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv', parse_dates=['date_recorded']).set_index('date_recorded')\n",
        "    \n",
        "#     # When columns have zeros and shouldn't, they are like null values.\n",
        "#     # So we will replace the zeros with nulls, and impute missing values later.\n",
        "#     # Also create a \"missing indicator\" column, because the fact that\n",
        "#     # values are missing may be a predictive signal.\n",
        "#     cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "#                        'gps_height', 'population']\n",
        "#     for col in cols_with_zeros:\n",
        "#         df[col] = df[col].replace(0, np.nan)\n",
        "#         df[col+'_MISSING'] = df[col].isnull()\n",
        "            \n",
        "#     # Drop duplicate columns\n",
        "#     duplicates = ['quantity_group', 'payment_type']\n",
        "#     df = df.drop(columns=duplicates)\n",
        "    \n",
        "#     # Drop recorded_by (never varies) and id (always varies, random)\n",
        "#     unusable_variance = ['recorded_by', 'id']\n",
        "#     df = df.drop(columns=unusable_variance)\n",
        "    \n",
        "    \n",
        "#     # Edftract components from date_recorded, then drop the original column\n",
        "#     df['year_recorded'] = df.index.year\n",
        "#     df['month_recorded'] = df.index.month\n",
        "#     df['day_recorded'] = df.index.day\n",
        "\n",
        "    # # Engineer feature: how many years from construction_year to date_recorded\n",
        "    # df['years'] = df['year_recorded'] - df['construction_year']\n",
        "    # df['years_MISSING'] = df['years'].isnull()\n",
        "    \n",
        "    # # return the wrangled dataframe\n",
        "    # return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "4Qr-zUaAWZdf",
        "outputId": "7941853a-d390-4daf-91b7-5d99c96be2e1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BerkeleyHeightstownship</th>\n",
              "      <th>NJ</th>\n",
              "      <th>39</th>\n",
              "      <th>5320</th>\n",
              "      <th>1</th>\n",
              "      <th>11980</th>\n",
              "      <th>3.1</th>\n",
              "      <th>1.37</th>\n",
              "      <th>91.78</th>\n",
              "      <th>6.5</th>\n",
              "      <th>1.88</th>\n",
              "      <th>12.47</th>\n",
              "      <th>21.44</th>\n",
              "      <th>10.93</th>\n",
              "      <th>11.33</th>\n",
              "      <th>11980.1</th>\n",
              "      <th>100</th>\n",
              "      <th>75122</th>\n",
              "      <th>89.24</th>\n",
              "      <th>1.55</th>\n",
              "      <th>70.2</th>\n",
              "      <th>23.62</th>\n",
              "      <th>1.03</th>\n",
              "      <th>18.39</th>\n",
              "      <th>79584</th>\n",
              "      <th>29711</th>\n",
              "      <th>30233</th>\n",
              "      <th>13600</th>\n",
              "      <th>5725</th>\n",
              "      <th>27101</th>\n",
              "      <th>5115</th>\n",
              "      <th>22838</th>\n",
              "      <th>227</th>\n",
              "      <th>1.96</th>\n",
              "      <th>5.81</th>\n",
              "      <th>9.9</th>\n",
              "      <th>48.18</th>\n",
              "      <th>2.7</th>\n",
              "      <th>64.55</th>\n",
              "      <th>14.65</th>\n",
              "      <th>...</th>\n",
              "      <th>?.4</th>\n",
              "      <th>?.5</th>\n",
              "      <th>?.6</th>\n",
              "      <th>?.7</th>\n",
              "      <th>?.8</th>\n",
              "      <th>?.9</th>\n",
              "      <th>?.10</th>\n",
              "      <th>?.11</th>\n",
              "      <th>?.12</th>\n",
              "      <th>?.13</th>\n",
              "      <th>?.14</th>\n",
              "      <th>?.15</th>\n",
              "      <th>?.16</th>\n",
              "      <th>6.5.1</th>\n",
              "      <th>1845.9</th>\n",
              "      <th>9.63</th>\n",
              "      <th>?.17</th>\n",
              "      <th>?.18</th>\n",
              "      <th>?.19</th>\n",
              "      <th>?.20</th>\n",
              "      <th>0.2</th>\n",
              "      <th>?.21</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>1.1</th>\n",
              "      <th>8.2</th>\n",
              "      <th>4</th>\n",
              "      <th>32.81</th>\n",
              "      <th>14.1</th>\n",
              "      <th>114.85</th>\n",
              "      <th>138</th>\n",
              "      <th>1132.08</th>\n",
              "      <th>16</th>\n",
              "      <th>131.26</th>\n",
              "      <th>2</th>\n",
              "      <th>16.41</th>\n",
              "      <th>41.02</th>\n",
              "      <th>1394.59</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Marpletownship</td>\n",
              "      <td>PA</td>\n",
              "      <td>45.0</td>\n",
              "      <td>47616.0</td>\n",
              "      <td>1</td>\n",
              "      <td>23123</td>\n",
              "      <td>2.82</td>\n",
              "      <td>0.80</td>\n",
              "      <td>95.57</td>\n",
              "      <td>3.44</td>\n",
              "      <td>0.85</td>\n",
              "      <td>11.01</td>\n",
              "      <td>21.30</td>\n",
              "      <td>10.48</td>\n",
              "      <td>17.18</td>\n",
              "      <td>23123</td>\n",
              "      <td>100.0</td>\n",
              "      <td>47917</td>\n",
              "      <td>78.99</td>\n",
              "      <td>1.11</td>\n",
              "      <td>64.11</td>\n",
              "      <td>35.50</td>\n",
              "      <td>2.75</td>\n",
              "      <td>22.85</td>\n",
              "      <td>55323</td>\n",
              "      <td>20148</td>\n",
              "      <td>20191</td>\n",
              "      <td>18137</td>\n",
              "      <td>0</td>\n",
              "      <td>20074</td>\n",
              "      <td>5250.0</td>\n",
              "      <td>12222</td>\n",
              "      <td>885</td>\n",
              "      <td>3.98</td>\n",
              "      <td>5.61</td>\n",
              "      <td>13.72</td>\n",
              "      <td>29.89</td>\n",
              "      <td>2.43</td>\n",
              "      <td>61.96</td>\n",
              "      <td>12.26</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.6</td>\n",
              "      <td>2186.7</td>\n",
              "      <td>3.84</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>5.0</td>\n",
              "      <td>21.26</td>\n",
              "      <td>24.0</td>\n",
              "      <td>102.05</td>\n",
              "      <td>57.0</td>\n",
              "      <td>242.37</td>\n",
              "      <td>376.0</td>\n",
              "      <td>1598.78</td>\n",
              "      <td>26.0</td>\n",
              "      <td>110.55</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>127.56</td>\n",
              "      <td>1955.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tigardcity</td>\n",
              "      <td>OR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>29344</td>\n",
              "      <td>2.43</td>\n",
              "      <td>0.74</td>\n",
              "      <td>94.33</td>\n",
              "      <td>3.43</td>\n",
              "      <td>2.35</td>\n",
              "      <td>11.36</td>\n",
              "      <td>25.88</td>\n",
              "      <td>11.01</td>\n",
              "      <td>10.28</td>\n",
              "      <td>29344</td>\n",
              "      <td>100.0</td>\n",
              "      <td>35669</td>\n",
              "      <td>82.00</td>\n",
              "      <td>1.15</td>\n",
              "      <td>55.73</td>\n",
              "      <td>22.25</td>\n",
              "      <td>2.94</td>\n",
              "      <td>14.56</td>\n",
              "      <td>42112</td>\n",
              "      <td>16946</td>\n",
              "      <td>17103</td>\n",
              "      <td>16644</td>\n",
              "      <td>21606</td>\n",
              "      <td>15528</td>\n",
              "      <td>5954.0</td>\n",
              "      <td>8405</td>\n",
              "      <td>1389</td>\n",
              "      <td>4.75</td>\n",
              "      <td>2.80</td>\n",
              "      <td>9.09</td>\n",
              "      <td>30.13</td>\n",
              "      <td>4.01</td>\n",
              "      <td>69.80</td>\n",
              "      <td>15.95</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10.6</td>\n",
              "      <td>2780.9</td>\n",
              "      <td>4.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>8.30</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.60</td>\n",
              "      <td>56.0</td>\n",
              "      <td>154.95</td>\n",
              "      <td>14.0</td>\n",
              "      <td>38.74</td>\n",
              "      <td>274.0</td>\n",
              "      <td>758.14</td>\n",
              "      <td>1797.0</td>\n",
              "      <td>4972.19</td>\n",
              "      <td>136.0</td>\n",
              "      <td>376.30</td>\n",
              "      <td>22.0</td>\n",
              "      <td>60.87</td>\n",
              "      <td>218.59</td>\n",
              "      <td>6167.51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gloversvillecity</td>\n",
              "      <td>NY</td>\n",
              "      <td>35.0</td>\n",
              "      <td>29443.0</td>\n",
              "      <td>1</td>\n",
              "      <td>16656</td>\n",
              "      <td>2.40</td>\n",
              "      <td>1.70</td>\n",
              "      <td>97.35</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.70</td>\n",
              "      <td>12.55</td>\n",
              "      <td>25.20</td>\n",
              "      <td>12.19</td>\n",
              "      <td>17.57</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20580</td>\n",
              "      <td>68.15</td>\n",
              "      <td>0.24</td>\n",
              "      <td>38.95</td>\n",
              "      <td>39.48</td>\n",
              "      <td>11.71</td>\n",
              "      <td>18.33</td>\n",
              "      <td>26501</td>\n",
              "      <td>10810</td>\n",
              "      <td>10909</td>\n",
              "      <td>9984</td>\n",
              "      <td>4941</td>\n",
              "      <td>3541</td>\n",
              "      <td>2451.0</td>\n",
              "      <td>4391</td>\n",
              "      <td>2831</td>\n",
              "      <td>17.23</td>\n",
              "      <td>11.05</td>\n",
              "      <td>33.68</td>\n",
              "      <td>10.81</td>\n",
              "      <td>9.86</td>\n",
              "      <td>54.74</td>\n",
              "      <td>31.22</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.2</td>\n",
              "      <td>3217.7</td>\n",
              "      <td>3.31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>10.0</td>\n",
              "      <td>57.86</td>\n",
              "      <td>10.0</td>\n",
              "      <td>57.86</td>\n",
              "      <td>33.0</td>\n",
              "      <td>190.93</td>\n",
              "      <td>225.0</td>\n",
              "      <td>1301.78</td>\n",
              "      <td>716.0</td>\n",
              "      <td>4142.56</td>\n",
              "      <td>47.0</td>\n",
              "      <td>271.93</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>306.64</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bemidjicity</td>\n",
              "      <td>MN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5068.0</td>\n",
              "      <td>1</td>\n",
              "      <td>11245</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.53</td>\n",
              "      <td>89.16</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.52</td>\n",
              "      <td>24.46</td>\n",
              "      <td>40.53</td>\n",
              "      <td>28.69</td>\n",
              "      <td>12.65</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17390</td>\n",
              "      <td>69.33</td>\n",
              "      <td>0.55</td>\n",
              "      <td>42.82</td>\n",
              "      <td>32.16</td>\n",
              "      <td>11.21</td>\n",
              "      <td>14.43</td>\n",
              "      <td>24018</td>\n",
              "      <td>8483</td>\n",
              "      <td>9009</td>\n",
              "      <td>887</td>\n",
              "      <td>4425</td>\n",
              "      <td>3352</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>1328</td>\n",
              "      <td>2855</td>\n",
              "      <td>29.99</td>\n",
              "      <td>12.15</td>\n",
              "      <td>23.06</td>\n",
              "      <td>25.28</td>\n",
              "      <td>9.08</td>\n",
              "      <td>52.44</td>\n",
              "      <td>6.89</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11.5</td>\n",
              "      <td>974.2</td>\n",
              "      <td>0.38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>32.04</td>\n",
              "      <td>14.0</td>\n",
              "      <td>112.14</td>\n",
              "      <td>91.0</td>\n",
              "      <td>728.93</td>\n",
              "      <td>1060.0</td>\n",
              "      <td>8490.87</td>\n",
              "      <td>91.0</td>\n",
              "      <td>728.93</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.05</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9988.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Springfieldcity</td>\n",
              "      <td>MO</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>140494</td>\n",
              "      <td>2.45</td>\n",
              "      <td>2.51</td>\n",
              "      <td>95.65</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.95</td>\n",
              "      <td>18.09</td>\n",
              "      <td>32.89</td>\n",
              "      <td>20.04</td>\n",
              "      <td>13.26</td>\n",
              "      <td>140494</td>\n",
              "      <td>100.0</td>\n",
              "      <td>21577</td>\n",
              "      <td>75.78</td>\n",
              "      <td>1.00</td>\n",
              "      <td>41.15</td>\n",
              "      <td>29.31</td>\n",
              "      <td>7.12</td>\n",
              "      <td>14.09</td>\n",
              "      <td>27705</td>\n",
              "      <td>11878</td>\n",
              "      <td>12029</td>\n",
              "      <td>7382</td>\n",
              "      <td>10264</td>\n",
              "      <td>10753</td>\n",
              "      <td>7192.0</td>\n",
              "      <td>8104</td>\n",
              "      <td>23223</td>\n",
              "      <td>17.78</td>\n",
              "      <td>8.76</td>\n",
              "      <td>23.03</td>\n",
              "      <td>20.66</td>\n",
              "      <td>5.72</td>\n",
              "      <td>59.02</td>\n",
              "      <td>14.31</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70.4</td>\n",
              "      <td>1995.7</td>\n",
              "      <td>0.97</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>4.63</td>\n",
              "      <td>77.0</td>\n",
              "      <td>50.98</td>\n",
              "      <td>136.0</td>\n",
              "      <td>90.05</td>\n",
              "      <td>449.0</td>\n",
              "      <td>297.29</td>\n",
              "      <td>2094.0</td>\n",
              "      <td>1386.46</td>\n",
              "      <td>7690.0</td>\n",
              "      <td>5091.64</td>\n",
              "      <td>454.0</td>\n",
              "      <td>300.60</td>\n",
              "      <td>134.0</td>\n",
              "      <td>88.72</td>\n",
              "      <td>442.95</td>\n",
              "      <td>6867.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 147 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  BerkeleyHeightstownship  NJ    39     5320  ...      2  16.41   41.02  1394.59\n",
              "0          Marpletownship  PA  45.0  47616.0  ...    1.0   4.25  127.56  1955.95\n",
              "1              Tigardcity  OR   NaN      NaN  ...   22.0  60.87  218.59  6167.51\n",
              "2        Gloversvillecity  NY  35.0  29443.0  ...    NaN    NaN  306.64      NaN\n",
              "3             Bemidjicity  MN   7.0   5068.0  ...    5.0  40.05     NaN  9988.79\n",
              "4         Springfieldcity  MO   NaN      NaN  ...  134.0  88.72  442.95  6867.42\n",
              "\n",
              "[5 rows x 147 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRyLucWbW-zx",
        "outputId": "b2c735f1-6c30-4a19-fe96-187af3a73639"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2214, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXbSJmStPGao"
      },
      "source": [
        "df.columns=['communityname','State','countyCode','communityCode','fold','pop','perHoush','pctBlack','pctWhite','pctAsian','pctHisp','pct12-21',\n",
        "            'pct12-29','pct16-24','pct65up','persUrban','pctUrban','medIncome','pctWwage','pctWfarm','pctWdiv','pctWsocsec','pctPubAsst','pctRetire'\n",
        "            ,'medFamIncome','perCapInc','whitePerCap','blackPerCap','NAperCap','asianPerCap','otherPerCap','hispPerCap','persPoverty','pctPoverty'\n",
        "            ,'pctLowEdu','pctNotHSgrad','pctCollGrad','pctUnemploy','pctEmploy','pctEmployMfg','pctEmployProfServ','pctOccupManu','pctOccupMgmt'\n",
        "            ,'pctMaleDivorc','pctMaleNevMar','pctFemDivorc','pctAllDivorc','persPerFam','pct2Par','pctKids2Par','pctKids-4w2Par','pct12-17w2Par'\n",
        "            ,'pctWorkMom-6','pctWorkMom-18','kidsBornNevrMarr','pctKidsBornNevrMarr','numForeignBorn','pctFgnImmig-3','pctFgnImmig-5','pctFgnImmig-8'\n",
        "            ,'pctFgnImmig-10','pctImmig-3','pctImmig-5','pctImmig-8','pctImmig-10','pctSpeakOnlyEng','pctNotSpeakEng','pctLargHousFam','pctLargHous'\n",
        "            ,'persPerOccupHous','persPerOwnOccup','persPerRenterOccup','pctPersOwnOccup','pctPopDenseHous','pctSmallHousUnits','medNumBedrm','houseVacant',\n",
        "            'pctHousOccup','pctHousOwnerOccup','pctVacantBoarded','pctVacant6up','medYrHousBuilt','pctHousWOphone','pctHousWOplumb','ownHousLowQ'\n",
        "            ,'ownHousMed','ownHousUperQ','ownHousQrange','rentLowQ','rentMed','rentUpperQ','rentQrange','medGrossRent','medRentpctHousInc','medOwnCostpct'\n",
        "            ,'medOwnCostPctWO','persEmergShelt','persHomeless','pctForeignBorn','pctBornStateResid','pctSameHouse-5','pctSameCounty-5','pctSameState-5'\n",
        "            ,'numPolice','policePerPop','policeField','policeFieldPerPop','policeCalls','policCallPerPop','policCallPerOffic','policePerPop2'\n",
        "            ,'racialMatch','pctPolicWhite','pctPolicBlack','pctPolicHisp','pctPolicAsian','pctPolicMinority','officDrugUnits','numDiffDrugsSeiz'\n",
        "            ,'policAveOT','landArea','popDensity','pctUsePubTrans','policCarsAvail','policOperBudget','pctPolicPatrol','gangUnit','pctOfficDrugUnit'\n",
        "            ,'policBudgetPerPop','murders','murdPerPop','rapes','rapesPerPop','robberies','robbbPerPop','assaults','assaultPerPop','burglaries'\n",
        "            ,'burglPerPop','larcenies','larcPerPop','autoTheft','autoTheftPerPop','arsons','arsonsPerPop','violentPerPop','nonViolPerPop']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5IYmOQ6Y4kz"
      },
      "source": [
        "df = df.dropna(axis=0, how=\"any\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "R5_UPhDuWMnZ",
        "outputId": "a6f707c7-ddd3-40b6-f896-904bc90ca97a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>communityname</th>\n",
              "      <th>State</th>\n",
              "      <th>countyCode</th>\n",
              "      <th>communityCode</th>\n",
              "      <th>fold</th>\n",
              "      <th>pop</th>\n",
              "      <th>perHoush</th>\n",
              "      <th>pctBlack</th>\n",
              "      <th>pctWhite</th>\n",
              "      <th>pctAsian</th>\n",
              "      <th>pctHisp</th>\n",
              "      <th>pct12-21</th>\n",
              "      <th>pct12-29</th>\n",
              "      <th>pct16-24</th>\n",
              "      <th>pct65up</th>\n",
              "      <th>persUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>pctWwage</th>\n",
              "      <th>pctWfarm</th>\n",
              "      <th>pctWdiv</th>\n",
              "      <th>pctWsocsec</th>\n",
              "      <th>pctPubAsst</th>\n",
              "      <th>pctRetire</th>\n",
              "      <th>medFamIncome</th>\n",
              "      <th>perCapInc</th>\n",
              "      <th>whitePerCap</th>\n",
              "      <th>blackPerCap</th>\n",
              "      <th>NAperCap</th>\n",
              "      <th>asianPerCap</th>\n",
              "      <th>otherPerCap</th>\n",
              "      <th>hispPerCap</th>\n",
              "      <th>persPoverty</th>\n",
              "      <th>pctPoverty</th>\n",
              "      <th>pctLowEdu</th>\n",
              "      <th>pctNotHSgrad</th>\n",
              "      <th>pctCollGrad</th>\n",
              "      <th>pctUnemploy</th>\n",
              "      <th>pctEmploy</th>\n",
              "      <th>pctEmployMfg</th>\n",
              "      <th>...</th>\n",
              "      <th>policeCalls</th>\n",
              "      <th>policCallPerPop</th>\n",
              "      <th>policCallPerOffic</th>\n",
              "      <th>policePerPop2</th>\n",
              "      <th>racialMatch</th>\n",
              "      <th>pctPolicWhite</th>\n",
              "      <th>pctPolicBlack</th>\n",
              "      <th>pctPolicHisp</th>\n",
              "      <th>pctPolicAsian</th>\n",
              "      <th>pctPolicMinority</th>\n",
              "      <th>officDrugUnits</th>\n",
              "      <th>numDiffDrugsSeiz</th>\n",
              "      <th>policAveOT</th>\n",
              "      <th>landArea</th>\n",
              "      <th>popDensity</th>\n",
              "      <th>pctUsePubTrans</th>\n",
              "      <th>policCarsAvail</th>\n",
              "      <th>policOperBudget</th>\n",
              "      <th>pctPolicPatrol</th>\n",
              "      <th>gangUnit</th>\n",
              "      <th>pctOfficDrugUnit</th>\n",
              "      <th>policBudgetPerPop</th>\n",
              "      <th>murders</th>\n",
              "      <th>murdPerPop</th>\n",
              "      <th>rapes</th>\n",
              "      <th>rapesPerPop</th>\n",
              "      <th>robberies</th>\n",
              "      <th>robbbPerPop</th>\n",
              "      <th>assaults</th>\n",
              "      <th>assaultPerPop</th>\n",
              "      <th>burglaries</th>\n",
              "      <th>burglPerPop</th>\n",
              "      <th>larcenies</th>\n",
              "      <th>larcPerPop</th>\n",
              "      <th>autoTheft</th>\n",
              "      <th>autoTheftPerPop</th>\n",
              "      <th>arsons</th>\n",
              "      <th>arsonsPerPop</th>\n",
              "      <th>violentPerPop</th>\n",
              "      <th>nonViolPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Toledocity</td>\n",
              "      <td>OH</td>\n",
              "      <td>95.0</td>\n",
              "      <td>77000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>332943</td>\n",
              "      <td>2.54</td>\n",
              "      <td>19.70</td>\n",
              "      <td>76.96</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.97</td>\n",
              "      <td>14.78</td>\n",
              "      <td>28.65</td>\n",
              "      <td>14.52</td>\n",
              "      <td>12.25</td>\n",
              "      <td>332943</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24819</td>\n",
              "      <td>71.86</td>\n",
              "      <td>0.36</td>\n",
              "      <td>36.37</td>\n",
              "      <td>28.93</td>\n",
              "      <td>12.29</td>\n",
              "      <td>18.44</td>\n",
              "      <td>30980</td>\n",
              "      <td>11894</td>\n",
              "      <td>13077</td>\n",
              "      <td>7722</td>\n",
              "      <td>9450</td>\n",
              "      <td>12415</td>\n",
              "      <td>7272.0</td>\n",
              "      <td>7817</td>\n",
              "      <td>62426</td>\n",
              "      <td>19.09</td>\n",
              "      <td>8.57</td>\n",
              "      <td>26.84</td>\n",
              "      <td>14.06</td>\n",
              "      <td>9.92</td>\n",
              "      <td>55.56</td>\n",
              "      <td>19.58</td>\n",
              "      <td>...</td>\n",
              "      <td>351211.0</td>\n",
              "      <td>108407.80</td>\n",
              "      <td>514.2</td>\n",
              "      <td>210.8</td>\n",
              "      <td>97.91</td>\n",
              "      <td>78.77</td>\n",
              "      <td>16.98</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.08</td>\n",
              "      <td>30.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>89.3</td>\n",
              "      <td>83.5</td>\n",
              "      <td>3988.5</td>\n",
              "      <td>3.00</td>\n",
              "      <td>222.0</td>\n",
              "      <td>41348280.0</td>\n",
              "      <td>80.67</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.39</td>\n",
              "      <td>127629.2</td>\n",
              "      <td>45</td>\n",
              "      <td>13.89</td>\n",
              "      <td>357.0</td>\n",
              "      <td>110.19</td>\n",
              "      <td>1594.0</td>\n",
              "      <td>492.02</td>\n",
              "      <td>1195.0</td>\n",
              "      <td>368.86</td>\n",
              "      <td>5502.0</td>\n",
              "      <td>1698.29</td>\n",
              "      <td>15251.0</td>\n",
              "      <td>4707.51</td>\n",
              "      <td>4517.0</td>\n",
              "      <td>1394.26</td>\n",
              "      <td>357.0</td>\n",
              "      <td>110.19</td>\n",
              "      <td>984.96</td>\n",
              "      <td>7910.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Philadelphiacity</td>\n",
              "      <td>PA</td>\n",
              "      <td>101.0</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1585577</td>\n",
              "      <td>2.63</td>\n",
              "      <td>39.86</td>\n",
              "      <td>53.52</td>\n",
              "      <td>2.74</td>\n",
              "      <td>5.63</td>\n",
              "      <td>13.92</td>\n",
              "      <td>28.02</td>\n",
              "      <td>14.12</td>\n",
              "      <td>13.74</td>\n",
              "      <td>1585577</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24603</td>\n",
              "      <td>70.12</td>\n",
              "      <td>0.35</td>\n",
              "      <td>32.15</td>\n",
              "      <td>31.63</td>\n",
              "      <td>13.98</td>\n",
              "      <td>18.20</td>\n",
              "      <td>30140</td>\n",
              "      <td>12091</td>\n",
              "      <td>15027</td>\n",
              "      <td>9061</td>\n",
              "      <td>10146</td>\n",
              "      <td>8285</td>\n",
              "      <td>5083.0</td>\n",
              "      <td>6053</td>\n",
              "      <td>313374</td>\n",
              "      <td>20.27</td>\n",
              "      <td>11.29</td>\n",
              "      <td>35.69</td>\n",
              "      <td>15.22</td>\n",
              "      <td>9.62</td>\n",
              "      <td>52.77</td>\n",
              "      <td>13.58</td>\n",
              "      <td>...</td>\n",
              "      <td>5480855.0</td>\n",
              "      <td>358261.41</td>\n",
              "      <td>840.2</td>\n",
              "      <td>426.4</td>\n",
              "      <td>79.54</td>\n",
              "      <td>73.48</td>\n",
              "      <td>23.18</td>\n",
              "      <td>2.84</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.95</td>\n",
              "      <td>273.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>39.9</td>\n",
              "      <td>140.0</td>\n",
              "      <td>11326.0</td>\n",
              "      <td>29.31</td>\n",
              "      <td>822.0</td>\n",
              "      <td>287578496.0</td>\n",
              "      <td>99.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.19</td>\n",
              "      <td>187978.5</td>\n",
              "      <td>439</td>\n",
              "      <td>28.70</td>\n",
              "      <td>785.0</td>\n",
              "      <td>51.31</td>\n",
              "      <td>11531.0</td>\n",
              "      <td>753.74</td>\n",
              "      <td>6821.0</td>\n",
              "      <td>445.86</td>\n",
              "      <td>15117.0</td>\n",
              "      <td>988.14</td>\n",
              "      <td>39181.0</td>\n",
              "      <td>2561.10</td>\n",
              "      <td>23785.0</td>\n",
              "      <td>1554.73</td>\n",
              "      <td>2282.0</td>\n",
              "      <td>149.17</td>\n",
              "      <td>1279.60</td>\n",
              "      <td>5253.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Lynchburgcity</td>\n",
              "      <td>VA</td>\n",
              "      <td>680.0</td>\n",
              "      <td>47672.0</td>\n",
              "      <td>1</td>\n",
              "      <td>66049</td>\n",
              "      <td>2.63</td>\n",
              "      <td>26.41</td>\n",
              "      <td>72.45</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.72</td>\n",
              "      <td>17.79</td>\n",
              "      <td>29.84</td>\n",
              "      <td>18.19</td>\n",
              "      <td>14.33</td>\n",
              "      <td>66049</td>\n",
              "      <td>100.0</td>\n",
              "      <td>23726</td>\n",
              "      <td>72.25</td>\n",
              "      <td>0.63</td>\n",
              "      <td>39.06</td>\n",
              "      <td>35.02</td>\n",
              "      <td>7.54</td>\n",
              "      <td>17.20</td>\n",
              "      <td>30141</td>\n",
              "      <td>12657</td>\n",
              "      <td>14721</td>\n",
              "      <td>7200</td>\n",
              "      <td>12833</td>\n",
              "      <td>6139</td>\n",
              "      <td>8400.0</td>\n",
              "      <td>7231</td>\n",
              "      <td>9889</td>\n",
              "      <td>16.45</td>\n",
              "      <td>13.61</td>\n",
              "      <td>30.52</td>\n",
              "      <td>21.74</td>\n",
              "      <td>5.97</td>\n",
              "      <td>56.27</td>\n",
              "      <td>19.31</td>\n",
              "      <td>...</td>\n",
              "      <td>61164.0</td>\n",
              "      <td>91072.10</td>\n",
              "      <td>443.2</td>\n",
              "      <td>205.5</td>\n",
              "      <td>81.87</td>\n",
              "      <td>90.58</td>\n",
              "      <td>9.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.42</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>38.7</td>\n",
              "      <td>51.2</td>\n",
              "      <td>1290.5</td>\n",
              "      <td>3.33</td>\n",
              "      <td>62.0</td>\n",
              "      <td>5585480.0</td>\n",
              "      <td>89.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.80</td>\n",
              "      <td>83166.8</td>\n",
              "      <td>3</td>\n",
              "      <td>4.47</td>\n",
              "      <td>45.0</td>\n",
              "      <td>67.00</td>\n",
              "      <td>107.0</td>\n",
              "      <td>159.32</td>\n",
              "      <td>351.0</td>\n",
              "      <td>522.63</td>\n",
              "      <td>560.0</td>\n",
              "      <td>833.83</td>\n",
              "      <td>2316.0</td>\n",
              "      <td>3448.48</td>\n",
              "      <td>184.0</td>\n",
              "      <td>273.97</td>\n",
              "      <td>50.0</td>\n",
              "      <td>74.45</td>\n",
              "      <td>753.42</td>\n",
              "      <td>4630.73</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>NewHaventown</td>\n",
              "      <td>CT</td>\n",
              "      <td>9.0</td>\n",
              "      <td>52070.0</td>\n",
              "      <td>1</td>\n",
              "      <td>130474</td>\n",
              "      <td>2.66</td>\n",
              "      <td>36.14</td>\n",
              "      <td>53.85</td>\n",
              "      <td>2.41</td>\n",
              "      <td>13.22</td>\n",
              "      <td>17.06</td>\n",
              "      <td>34.55</td>\n",
              "      <td>19.17</td>\n",
              "      <td>10.81</td>\n",
              "      <td>130474</td>\n",
              "      <td>100.0</td>\n",
              "      <td>25811</td>\n",
              "      <td>73.04</td>\n",
              "      <td>0.47</td>\n",
              "      <td>37.07</td>\n",
              "      <td>26.28</td>\n",
              "      <td>14.61</td>\n",
              "      <td>12.75</td>\n",
              "      <td>31163</td>\n",
              "      <td>12968</td>\n",
              "      <td>16127</td>\n",
              "      <td>9616</td>\n",
              "      <td>7750</td>\n",
              "      <td>11739</td>\n",
              "      <td>7014.0</td>\n",
              "      <td>7420</td>\n",
              "      <td>25481</td>\n",
              "      <td>21.29</td>\n",
              "      <td>11.86</td>\n",
              "      <td>28.97</td>\n",
              "      <td>26.70</td>\n",
              "      <td>9.25</td>\n",
              "      <td>56.71</td>\n",
              "      <td>16.41</td>\n",
              "      <td>...</td>\n",
              "      <td>145000.0</td>\n",
              "      <td>121233.40</td>\n",
              "      <td>371.8</td>\n",
              "      <td>326.1</td>\n",
              "      <td>74.62</td>\n",
              "      <td>79.23</td>\n",
              "      <td>17.44</td>\n",
              "      <td>3.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.77</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>167.4</td>\n",
              "      <td>19.5</td>\n",
              "      <td>6679.9</td>\n",
              "      <td>9.54</td>\n",
              "      <td>100.0</td>\n",
              "      <td>17939552.0</td>\n",
              "      <td>89.74</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.08</td>\n",
              "      <td>149991.2</td>\n",
              "      <td>22</td>\n",
              "      <td>18.39</td>\n",
              "      <td>130.0</td>\n",
              "      <td>108.69</td>\n",
              "      <td>1238.0</td>\n",
              "      <td>1035.08</td>\n",
              "      <td>1154.0</td>\n",
              "      <td>964.85</td>\n",
              "      <td>3417.0</td>\n",
              "      <td>2856.93</td>\n",
              "      <td>7719.0</td>\n",
              "      <td>6453.80</td>\n",
              "      <td>1873.0</td>\n",
              "      <td>1566.00</td>\n",
              "      <td>134.0</td>\n",
              "      <td>112.04</td>\n",
              "      <td>2127.02</td>\n",
              "      <td>10988.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>Springfieldcity</td>\n",
              "      <td>OH</td>\n",
              "      <td>23.0</td>\n",
              "      <td>74118.0</td>\n",
              "      <td>1</td>\n",
              "      <td>70487</td>\n",
              "      <td>2.59</td>\n",
              "      <td>17.38</td>\n",
              "      <td>81.61</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.65</td>\n",
              "      <td>16.05</td>\n",
              "      <td>28.26</td>\n",
              "      <td>15.37</td>\n",
              "      <td>13.59</td>\n",
              "      <td>70487</td>\n",
              "      <td>100.0</td>\n",
              "      <td>21407</td>\n",
              "      <td>69.94</td>\n",
              "      <td>0.31</td>\n",
              "      <td>30.37</td>\n",
              "      <td>31.35</td>\n",
              "      <td>14.47</td>\n",
              "      <td>20.99</td>\n",
              "      <td>26838</td>\n",
              "      <td>10648</td>\n",
              "      <td>11196</td>\n",
              "      <td>8112</td>\n",
              "      <td>5418</td>\n",
              "      <td>15847</td>\n",
              "      <td>3530.0</td>\n",
              "      <td>7654</td>\n",
              "      <td>13999</td>\n",
              "      <td>20.87</td>\n",
              "      <td>9.79</td>\n",
              "      <td>31.67</td>\n",
              "      <td>10.88</td>\n",
              "      <td>8.74</td>\n",
              "      <td>53.25</td>\n",
              "      <td>23.26</td>\n",
              "      <td>...</td>\n",
              "      <td>108785.0</td>\n",
              "      <td>153872.80</td>\n",
              "      <td>1077.1</td>\n",
              "      <td>142.9</td>\n",
              "      <td>86.22</td>\n",
              "      <td>94.06</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.94</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>52.8</td>\n",
              "      <td>20.2</td>\n",
              "      <td>3485.1</td>\n",
              "      <td>1.06</td>\n",
              "      <td>45.0</td>\n",
              "      <td>5653511.0</td>\n",
              "      <td>93.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.94</td>\n",
              "      <td>79967.1</td>\n",
              "      <td>6</td>\n",
              "      <td>8.49</td>\n",
              "      <td>59.0</td>\n",
              "      <td>83.45</td>\n",
              "      <td>208.0</td>\n",
              "      <td>294.21</td>\n",
              "      <td>786.0</td>\n",
              "      <td>1111.77</td>\n",
              "      <td>963.0</td>\n",
              "      <td>1362.13</td>\n",
              "      <td>4048.0</td>\n",
              "      <td>5725.76</td>\n",
              "      <td>457.0</td>\n",
              "      <td>646.41</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.49</td>\n",
              "      <td>1497.92</td>\n",
              "      <td>7742.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 147 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        communityname State  ...  violentPerPop  nonViolPerPop\n",
              "53         Toledocity    OH  ...         984.96        7910.25\n",
              "54   Philadelphiacity    PA  ...        1279.60        5253.14\n",
              "57      Lynchburgcity    VA  ...         753.42        4630.73\n",
              "98       NewHaventown    CT  ...        2127.02       10988.76\n",
              "121   Springfieldcity    OH  ...        1497.92        7742.79\n",
              "\n",
              "[5 rows x 147 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY-9PwzyW59n",
        "outputId": "5ee609ef-6d49-4ef3-a7d1-cfe66ab30a8e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(111, 147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qyVP-T_gIbf"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTvO-OatgIbg"
      },
      "source": [
        "target = 'violentPerPop'\n",
        "X = df.drop(columns=target)\n",
        "y = df[target]\n",
        "\n",
        "# Train-validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoScYAsogIbg"
      },
      "source": [
        "# Establish Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Djeu0bKgIbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253e0fc1-6855-4ccc-de12-c2c2e6d9d5c3"
      },
      "source": [
        "print('Baseline Accuracy Score:', y_train.value_counts(normalize=True).max())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.011363636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3jiNoOEgIbi"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rl6ssNJngIbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4af07c21-bd7c-423a-e9f9-79d474b26e0e"
      },
      "source": [
        "# model_skgb = make_pipeline(\n",
        "#     OrdinalEncoder(),\n",
        "#     SimpleImputer(),\n",
        "#     GradientBoostingClassifier(random_state=42)\n",
        "# )\n",
        "\n",
        "# model_skgb.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-b343eb99bb35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_skgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    352\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_no_change\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_validate_y\u001b[0;34m(self, y, sample_weight)\u001b[0m\n\u001b[1;32m   2088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2090\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2091\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0mn_trim_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kA8HTJLgIbj"
      },
      "source": [
        "model_xgb = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(random_state=42,\n",
        "                  n_jobs=-1)\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfmiBiimgIbj"
      },
      "source": [
        "# Check Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYpWiTCrgIbj"
      },
      "source": [
        "print('sklearn Training Accuracy:', model_skgb.score(X_train, y_train))\n",
        "print('sklearn Validation Accuracy:', model_skgb.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mr5-vCHgIbj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "90be41a7-5770-4231-d5f0-67bb33c0f9cb"
      },
      "source": [
        "print('XGBoost Training Accuracy:', model_xgb.score(X_train, y_train))\n",
        "print('XGBoost Validation Accuracy:', model_xgb.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-e069f5931eb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost Training Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XGBoost Validation Accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_xgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0mscore_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mscore_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# No metrics support \"multiclass-multioutput\" format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: continuous is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djCjZ5WBgIbk"
      },
      "source": [
        "# Tuning / Communication\n",
        "\n",
        "- How can we determine or communicate which features are most important to our model when making predictions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AInnlEDgIbk"
      },
      "source": [
        "**Option 1:** Grab feature importances from our pipeline\n",
        "\n",
        "- **Plus:** Less computationally expensive.\n",
        "- **Minus:** Can be misleading.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl3WvMoKgIbl"
      },
      "source": [
        "importances = model_xgb.named_steps['xgbclassifier'].feature_importances_\n",
        "feature_names = X_train.columns\n",
        "feat_imp =  pd.Series(importances, index=feature_names).sort_values()\n",
        "\n",
        "feat_imp.tail(10).plot(kind='barh')\n",
        "plt.xlabel('Gini Importance')\n",
        "plt.ylabel('Feature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN1koMwpgIbl"
      },
      "source": [
        "**Option 2:** Drop-column Importance\n",
        "\n",
        "- Good, but computationally expensive because you have to train a model for each feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JTyo-zggIbm"
      },
      "source": [
        "col = 'quantity'\n",
        "\n",
        "model_w_col = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=25,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1)\n",
        ")\n",
        "\n",
        "model_w_col.fit(X_train, y_train);\n",
        "\n",
        "print(f'Training Accuracy w/ \"{col}\" included:', model_w_col.score(X_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak9KU9TUc8Uq"
      },
      "source": [
        "model_wo_col = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=25,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1)\n",
        ")\n",
        "\n",
        "model_wo_col.fit(X_train.drop(columns=col), y_train);\n",
        "\n",
        "print(f'Training Accuracy w/ \"{col}\" excluded:', \n",
        "      model_wo_col.score(X_val.drop(columns=col), y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v6DCsPHdvaf"
      },
      "source": [
        "print(f'Drop-column importance of \"{col}\":', 0.72037-0.678872)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xibNSssenaU"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLhviblHgIbn"
      },
      "source": [
        "**Option 3:** Permutation Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSJfrkpTgIbn"
      },
      "source": [
        "# By hand\n",
        "\n",
        "# Step 1: Choose my feature\n",
        "col = 'quantity'\n",
        "\n",
        "# Step 2: Train model w/ ALL features\n",
        "model_xgb = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(),\n",
        "    XGBClassifier(n_estimators=25,\n",
        "                  random_state=42,\n",
        "                  n_jobs=-1)\n",
        ")\n",
        "\n",
        "model_xgb.fit(X_train, y_train);\n",
        "\n",
        "# Step 3: Evaluate model using VALIDATION DATA.\n",
        "print('XGBoost Validation Accuracy:', model_xgb.score(X_val, y_val))\n",
        "\n",
        "# Step 4: In VALIDATION DATA, permute the feature we're evaluating\n",
        "X_val_perm = X_val.copy()\n",
        "X_val_perm[col] = np.random.permutation(X_val_perm[col])\n",
        "\n",
        "# Step 5: Calculate our error metric with the permuted data \n",
        "print(f'XGBoost Validation Accuracy w \"{col}\" permuted:', \n",
        "      model_xgb.score(X_val_perm, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmdoE2sNjsQL"
      },
      "source": [
        "# Using sklearn\n",
        "\n",
        "perm_imp = permutation_importance(\n",
        "    model_xgb,\n",
        "    X_val, \n",
        "    y_val,\n",
        "    n_repeats=5,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZp3hq1qk_u5"
      },
      "source": [
        "data = {'imp_mean': perm_imp['importances_mean'],\n",
        "      'imp_std': perm_imp['importances_std']}\n",
        "\n",
        "df = pd.DataFrame(data, index=X_val.columns).sort_values('imp_mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aGSObS7lYRB"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2M9eynglcoi"
      },
      "source": [
        "df['imp_mean'].tail(10).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QldPlD57l2Sn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}